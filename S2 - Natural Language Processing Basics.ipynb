{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b3d1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d26e9",
   "metadata": {},
   "source": [
    "## pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b72e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef43b1d",
   "metadata": {},
   "source": [
    "# Run in anaconda prompt\n",
    "python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df26dd3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a512abf93817>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#loading model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \"\"\"\n\u001b[1;32m---> 51\u001b[1;33m     return util.load_model(\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[index]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "#loading model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c066b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating object doc \n",
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b05740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc :\n",
    "    print(token.text ,      token.pos_ ,        token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d85633",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff574581",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c6911",
   "metadata": {},
   "source": [
    "https://spacy.io/api/annotation#pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348195d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u'Tesla is looking to enter Indian market in 2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc2:\n",
    "    print(token.text , token.pos_ , token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e86f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote = doc3[16:30]\n",
    "quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57208cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22490820",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4  = nlp(u\"This is first sen. This is 2nd sen . This is 3rd sen\")\n",
    "doc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cbf3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in doc4.sents :\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6190df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66a1911",
   "metadata": {},
   "source": [
    "#  Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d4ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string ='\"we\\'re moving to L.A.!\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2389ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f7db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa734a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc :\n",
    "    print(\"{}         {} \".format(token,token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052eadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b0c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67f085a",
   "metadata": {},
   "source": [
    "### Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015b5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc5 = nlp(u\"Apple to build a India  factory for $10 million \")\n",
    "\n",
    "for entity in doc5.ents:\n",
    "    print(entity)\n",
    "    print(entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a3fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc6 = nlp(u'Apple to build a Hong Kong factory for $6 Million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in doc6.ents:\n",
    "    print(entity)\n",
    "    print(entity.label_)\n",
    "    \n",
    "    print(spacy.explain(entity.label_))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c457ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunks in doc6.noun_chunks:\n",
    "    print(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf82131",
   "metadata": {},
   "source": [
    "# Tokenization Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535dc6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b03d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Apple is going to build a U.K. factory for $5 millions for producing Ipad's . \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff8e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc,style='dep' , jupyter=True ,options={'distance':110})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc , style='ent' , jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433bad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97007fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc7 = nlp(u\"India is a country with Uprising football & cricket talents as reported by T.O.I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac423bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc7:\n",
    "    print(f\"{token.text:10}   {token.dep_:10}  {token.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41428a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in doc7.ents:\n",
    "    print(entity ,entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df54bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc7 , style='dep' , options={'distance':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc7 , style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791f21a",
   "metadata": {},
   "source": [
    "# Stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e591290",
   "metadata": {},
   "source": [
    "     Removing end letters from a group of similar words so that we extract a {stemmed} meaningful word or \"root\"\n",
    "     Word Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969b2fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d82b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pstem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c88037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['ring','rings','rang' ,'ranged','wrong', 'wrongly','wronged']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d4b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words :\n",
    "    print(word +'------------'+ pstem.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb72a14",
   "metadata": {},
   "source": [
    "# !!!!!  SnowballStemmer is better than PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eb77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "ss = SnowballStemmer(language= 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words :\n",
    "    print(word +'  ------------  '+ ss.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f243532",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "        More informative than stemming hence opted by Spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8705bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"I am a runner running in a race because I love to run since I ran to win\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb549bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token , token.lemma , token.lemma_ , token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906d983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text):\n",
    "        for token in text:\n",
    "            print(f\"{token.text:10} {token.lemma:22} {token.lemma_:10} {token.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0f94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_lemmas(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b35f84",
   "metadata": {},
   "source": [
    " ###  Stopwords - Non useful words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb76136",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f75745",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['is'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b998d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.add('Rahul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ec6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['Rahul'].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800335cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61db13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.remove('Rahul')\n",
    "nlp.vocab['Rahul'].is_stop=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20760f14",
   "metadata": {},
   "source": [
    "# Phrase Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8421a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b50ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = [{'LOWER':'Rahul Hirondi'}]\n",
    "p2 = [{'LOWER':'Rahul'},{'LOWER':'Hirondi'}]\n",
    "p3 = [{'LOWER':'Rahul'},{'IS_PUNCT':True},{'LOWER':'Hirondi'}]\n",
    "\n",
    "matcher.add(str = 'Rahul Hirondi',[p1,p2,p3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d905a675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
